\documentclass{template}

\project{Project Report \\for the Computer Vision course}
\title{Multi-Camera 3D Ball Tracking System}
\author{Lorenzo Orsingher\\Alessia Pivotto}
\abst{
This report provides a comprehensive technical overview of the various tasks conducted for the project of the Computer Vision course. 
\\
Accurate tracking of objects in three-dimensional space is essential for sports analytics, where precise motion capture enhances performance analysis, training, and strategy development. 
This project uses the multi-camera system at Sambapolis facilities and aims to achieve high-precision 3D ball tracking. 

As a starting point we had a previous project developed by other students that covered the part of calibration of the cameras. 
However, we opted to rebuild the calibration process from the ground up, addressing limitations to deliver superior performance and reliability. 
The new calibration methodology introduces refined camera alignment techniques and an improved selection process for calibration frames. 
These enhancements ensure more precise calibration, facilitating seamless integration and alignment of multiple cameras.

In addition to technical refinements, the system features an intuitive user interface that simplifies the configuration and monitoring of the tracking setup. 
This interface supports users in managing camera positions, calibrating settings, and visualizing the tracking process, making the system accessible even to non-technical users.

Our enhanced system effectively tracks a ball across multiple video feeds, reconstructing its 3D trajectory with high accuracy. 
The system consistently provides accurate tracking data and 3D reconstructions, this efficiency and precision translate into more reliable data for performance analysis and tactical evaluations.

These advancements offer a robust, user-friendly solution tailored to the specific needs of sports analytics, providing valuable insights into ball dynamics and player interactions. 
This system has the potential to help sports teams analyze game play and improve training methodologies by delivering detailed, real-time tracking information with minimal setup time.

So, in this report we elucidate the methodologies employed to develop the project, and finally, the concluding section provides a comprehensive summary of the results obtained throughout the project. 
Additionally, it outlines potential avenues for further applications and future developments.
}
\supervisor{Nicolò Bisagno}

\begin{document}

\chapter{Calibration}\label{ch:in}
Our project at the Sambapolis sports facility in Trento involves a multi-camera system designed to capture and analyze ball trajectories. 
The primary steps in our calibration process include capturing multiple frames of a checkerboard, identifying reference points such as corners or line intersections of the field, computing the intrinsic and extrinsic camera parameters, and then refining and validating the calibration results.
A notable advancement in our process is the improved detection process of the checkerboard pattern, this chapter delves into our calibration methodology, with particular emphasis on these enhancements.

\section{Camera Calibration Overview}
\textbf{Insert images and snippets for the calibration steps}\\
Our camera calibration system is designed to streamline the calibration of multiple cameras through a user-friendly command-line interface. 
This tool allows users to select the cameras to be calibrated and define reference points efficiently, providing real-time visual feedback and 3D plotting. 
The calibration process involves several key steps, users initiate the calibration process by selecting the cameras from a predefined list. 
This selection can be executed directly from the command line, allowing for a swift setup and enabling the calibration of specific cameras based on the project requirements. 
After camera selection, users are prompted to identify and mark reference points. 
These points serve as a basis for calibration and are crucial for ensuring the accuracy of the system. 
The tool provides options for manual input or the use of pre-existing calibration data, enhancing flexibility and reusability of calibration results.
The core of the calibration process consists of the computation of intrinsic and extrinsic parameters of the cameras based on the reference points. 
Obtaining these parameters we can move on to validate the accuracy by comparing the computed camera parameters against known geometric relationships or previously established calibration data. 

\section{Improvements}
As in the previous project, we decided to use checkerboards in our calibration method. 
However, we insert some improvements such as a distance check and a system to fasten the pattern detection process.

\subsection{Distance Validation}
To ensure the quality and uniqueness of detected checkerboard patterns, the check distance function evaluates the distance of the current checkerboard's central point from all previously detected central points. 
The function calculates the Euclidean distance between the newly detected point and each previously recorded point, then, the new point is considered valid only if the distance is above a predefined threshold.

\subsection{Fast Pattern Detection}
The fast detection function begins by resizing the image to a lower resolution, which speeds up the detection process while maintaining the pattern’s visibility. 
It then identifies the checkerboard pattern in the resized image using the function get corners and check the distance using the check distance function.
If the detected pattern is sufficiently distinct from prior detections, the function refines the detection by calling get corners again on the original, high-resolution image to obtain more precise corner coordinates. 

\section{Visualization and Interaction}
As users interact with the system, during identification of the reference points, the visualizations update in real time. 
Indeed, we provide a little and minimal representation of the field with the key points highlighted, the current point is identified with a color, and as you proceed with identification the points already saved are also changed in color. 
This dynamic feedback loop ensures that users can immediately see the impact of their actions, leading to more precise and accurate calibration results.
Upon successful calibration, the system generates a comprehensive visualization of the field and the cameras' positions. The system produces a 3D plot that represents the field and the calibrated positions of the cameras. 
This plot provides a spatial overview, showing how each camera is oriented and positioned relative to the field.
Moreover, users can interactively explore the field through the synchronized views from all cameras. When a user selects a point in any camera view or on the 3D plot, the corresponding point is highlighted across all other camera views and on the 3D plot. 

\chapter{Ball Tracking Overview}
\textbf{Mi manca la parte di ricostruzione 3D}\\
In our Python-based project, we have developed scripts for efficient video processing and data augmentation, including a user interface for camera control, frame skipping, and playback. 
This chapter details our detection and tracking approach, utilizing YOLO for object detection, SlicedYOLO for high-resolution video processing, and scripts for data augmentation and annotation verification.

\section{Methodology}
To achieve robust object detection, we decide to utilize YOLO (You Only Look Once).

We start by loading a pretrained-by-us YOLO model, then, we employ a customized \texttt{SlicedYOLO} approach to manage high-resolution videos efficiently. 
This method divides video frames into overlapping slices, ensuring comprehensive coverage of the image for detection and optimizing computational efficiency, providing complete coverage of frames.

The script operates in a loop, sequentially processing frames captured by multiple cameras. 
It reads frames from each camera feed, applies the \texttt{SlicedYOLO} model for object detection, and highlights detected objects within each frame. 

\section{Data Augmentation}
Data augmentation is critical for enriching our dataset and improving model robustness. 
Introducing variability through augmentation enhances the quality and diversity of training data.

We apply transformations such as random cropping, horizontal flipping, and adjustments to brightness and contrast to improve the robustness of machine learning models trained on the data.

The script reads images and their corresponding bounding box labels in YOLO format. 
It applies the specified transformations and saves the augmented images and labels to a target dataset.

Visual validation ensures the quality of augmented data, indeed, transformed images with overlaid bounding boxes are displayed for inspection, allowing us to verify the effectiveness of the transformations.

\section{Annotation Quality Assurance}

The \texttt{checklabels.py} script is designed for visualizing bounding box annotations on images within a dataset. 
It serves as a tool for verifying the accuracy of these annotations.

The script provides a user-friendly interface for navigating through annotated images and inspecting bounding boxes.
Users can confirm the correctness of the annotations, ensuring reliable input data for subsequent machine learning tasks.

\chapter{Results and Conclusion}

Do we have some numeric comparison between our method and the previous one? Così facciamo la sezione per i confronti che piacciono tanto a Bisagno.
% Togli la cit solo dopo averne messa un'altra altrimenti latex si arrabbia.
\cite{gulawani2006cfd}

This report has outlined the development and implementation of a multi-camera 3D ball tracking system aimed at enhancing sports analytics. 
Our project, conducted at the Sambapolis sports facility in Trento, leverages advancements in camera calibration, object detection, and data augmentation to provide a robust and user-friendly solution for tracking ball trajectories across multiple video feeds.

We began by rebuilding the camera calibration process to improve precision and reliability. 
This new methodology incorporates refined techniques for camera alignment and calibration frame selection, ensuring superior performance and enabling accurate spatial data capture. 
The 3D plots and synchronized views provide a comprehensive understanding of the field, aiding in the identification and correction of camera placement issues. 
With its interactive command-line interface, users can easily manage calibrations, whether reusing existing ones or creating new setups, enhancing overall efficiency and flexibility.

In object detection, we utilized the YOLO model and introduced the \texttt{SlicedYOLO} approach that divides frames into overlapping slices, optimizing the detection process and ensuring comprehensive coverage. 

To enhance the dataset and model robustness, we implemented a data augmentation script that applies various transformations to enrich the training data. 
Visual validation steps further ensure the quality of the augmented data.

We even provide a user-friendly interface for verifying bounding box annotations, enhancing the accuracy and reliability of the dataset. 
This tool allows users to navigate through annotated images, inspect bounding boxes, and confirm their correctness.
\\
The advancements presented in this report offer a comprehensive solution for tracking ball dynamics and player interactions in sports settings. 
The high-precision 3D ball tracking system provides valuable insights into game play, aiding in performance analysis, training methodologies, and tactical evaluations. 
The integration of multiple camera feeds and the ability to handle high-resolution videos make the system suitable for various sports and scenarios, enhancing its versatility and applicability.

\section{Future Developments}
Non so cosa scrivere sinceramnete, o meglio si ma non sarebbe carino dire che in futuro non bisognerebbe allenare il modello coi dati di test...

\end{document}
